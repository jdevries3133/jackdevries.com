---
title: CAP Theorem Workshop
description: Learn about the CAP Theorem, and two related database concepts: "ACID" and "BASE"
created: 2022-12-09
---

# CAP Theorem Workshop

In mathematics, a theorem is a fact that can be proven to be true. For example,
the Pythagorean Theorem which states that the ratio between the sides of a
right triangle always equal `a^2 + b^2 = c^2`, where `a` and `b` edges form a
right angle, and `c` is the triangle's hypotenuse. Why is this fact true?
Mathematicians will always support their theorems with proofs, which are a mix
of prose and math equations that might themselves reference other theorems,
which themselves have proofs. As long as there are no cycles in a theorem's
chain of references, we feel pretty confident that the math works out.

In that sense, the CAP Theorem isn't really a theorem at all. It's only proof
is the experience of many software engineers. Like any engineering discipline,
software engineers value experience and pragmaticism highly, alongside the cold
hard truths we can discover through science. It's important to understand that
the CAP Theorem is the former. Try figuring out a way to solve it, you'd change
the world! _But you probably won't figure it out._

## First, a Thought Experiment

Before we dive in, try to design the following system. Here is your spec:

> Design a name registration service. The service can be a HTTP/JSON Web API.
> Every time someone is born, the hospital will send a POST to `/name`. Unlike
> real names, our name service will enforce uniqueness. Duplicate names should
> return a `400 Bad Request` error, and valid unique names can return `201
> Created`.
>
> It is critical to our society that no one gets the same name; all names must
> be unique. It must be impossible for the same name to be created twice, even
> if identical names are sent to our service in close succession.
>
> This service is critical. It must be up 99.99% of the time. If it goes down,
> newborns cannot be billed for or provided healthcare ðŸ‡ºðŸ‡¸
>
> Boss man says we will keep all data in the same database, no need for any
> unnecessary complexity in the system or additional cost.

Do you think you could design such a system? Share your thoughts in the
comments at the bottom!

## Breaking Down CAP

CAP stands for:

- Consistency
- Availability
- Partition Tolerance

The Theorem states that for any software system, you can have 2, but you cannot
have all three. To understand the consequences of this, let's study the
definition of each term.

### Consistency

Consistency is the amount of time it takes for any data write into the system
to affect a data read out of the system. Our name registration service is
write-only, but this is captured by the requirement that we can't accidentally
create the same name twice.

Though it might appear innocuous, this places a lot of strain on our system.
Every time we want to create a name, we'll have to check the list of all
existing names. If we sort our names alphabetically, we can perform a binary
search for duplicates, but even a binary search still takes `O (log n)` time.
For arbitrarily large inputs, the amount of time it will take never stops
increasing. Our universe's infinite RAM helps because we don't need to consider
round trip time of a disk or network that would occur in a real system. Still,
at some point these uniqueness checks will start to drag. The fact that we have
to perform a full check before every write is going to make that pain greater.

Additionally, our consistency requirement limits the extent to which our system
can benefit from parallel processing. For ultra high consistency, two servers
can't even receive registration requests at the same time. They would have to
check with each other as well as the existing names before being able to
register a name, and the cross-talk cost would wipe out the benefit of
concurrency.

Now, we have a system that has to do a lot of work every time it receives a
request, and cannot use concurrency because of the consistency requirement.

### Availability

Availability is whether or not the service is able to receive and respond to
requests from clients. Availability is usually expressed as a percentage of
time. For example, a service that is 80% available will only be online 80% of
the time.

For most services, there is also some threshold of latency where the service
may as well be unavailable. If a web browser request timeout duration is 30
seconds, and a request takes more than 30 seconds to respond, the service is,
for all intents and purposes, unavailable.

Systems with high throughput will have a greater challenge to meet availability
needs, as well.

As we said, our name registration service needs 99.99% uptime. Since it's a web
service, we can assume a 30 second latency threshold. Unfortunately, we don't
even need a lot of throughout to fail. Once we have a gargantuan number of
names, and we need to check them all for duplicates, it is eventually
inevitable that it will take more than 30 seconds to service a request.

It sounds a bit contrived but consider such a system in China (which probably
does exist!).

```
1.4 billion people * 255 bytes per name = 357 terabytes
```

Even with the concession of unlimited RAM and binary search, good luck scanning
357 terabytes of names for duplicates. You ain't gonna finish in 30 seconds.
Plus, you'll need to serve 28 requests per minute on average. I'm not sure what
the peak capacity above that average should look like.

Suffice it to say, _oof._

### Partition Tolerance

Partition tolerance is the extent to which data in a system can be partitioned.
Consider a social network where you need to travel deep through networks of
friends. This is a system that is almost impossible to partition. You might try
to group people by their social groups, but every person that makes an
international friend crosses what would otherwise be a partition boundary and
gives you a headache. It turns out that these highly connected problem spaces
are very intolerant to partitioning.

Our name registry, on the other hand, can be rescued by partitioning. Recall
the stupid reason we thought we couldn't partition:

> Boss man says we will keep all data in the same database, no need for any
> unnecessary complexity in the system or additional cost.

Looks like it's time for a conversation with boss man. If consistency and
availability are important, we must partition. Our main issue is that every new
name forces us to stop the world and check every existing name. For a registry
in the U.S. (_I'll step away from China for my lack of knowledge of Mandarin_),
we can easily partition our names into 26 data stores based on the first
letter! If that's still too much data, we can partition based on the first two
letters. Names starting with `Ja` can go into a different database than those
starting with `Jo`.

Partitioning always implies the need for some additional logic that we will
take responsibility for so that we visit the right data for the right request.
If that logic is easy to write, like in our naming registry, we have great
partition tolerance and we can provide both consistency and availability
through partitioning.

Partitioning is probably the most complex part of the CAP Theorem. Remember
that there are systems that just can't be partitioned, or can't be partitioned
well. With that in mind, let's talk about the grey area in detail.

## CAP is not All or Nothing

The CAP Theorem says that a system with requirements for _absolute_ consistency
_must_ either have low availability or high partition tolerance. Systems that
must be _highly available,_ cannot be perfectly consistent, or must have
partition tolerance. Problems that can't be partitioned well must compromise on
availability or consistency.

However, in software systems, there are grey areas everywhere. A system can
exist that provides some aspect of all three, but not everywhere.

A very common way of skirting away CAP Theorem are microservices. In some
sense, microservices do a bit of partitioning because they have separate data
stores. They also have a bit of low availability sometimes. Generally, the
larger system should be able to work around the outage of any specific
microservice. A system of many microservices also means that each service can
have different CAP properties. A core accounting service might have very high
latency, even waiting for humans to service certain requests. This means low
availability. Meanwhile, the e-commerce service can be inconsistent via
optimism. It can tell the customer that their order will be fulfilled, despite
the fact that it's not 100% certain that the accounting service will eventually
validate the transaction.

### Consistent-ish

Ask these questions to determine how much availability we need:

- How quickly do data reads need to match data writes?
- What will happen if we send old data for read requests?
- What race conditions can happen if data is out of sync?
- How much is the customer sad if their request is lost, or false positive
  results occur?

### Available-ish

Ask these questions to determine how much availability we need:

- Is the system 99% available, or 99.9999% available?
- What are the latency requirements?
- Can we still satisfy the customer if this service goes down?
- How much data is passing through this service?

## ACID Guarantees

At some point, some folks made some decisions about how a good database should
behave. The idea of ACID guarantees emerged in the 1980s. CAP Theorem emerged
in 1999.

Mistakes were made. Let's talk about it!

First, ACID stands for atomicity, consistency, isolation, and durability. These
properties are the default for any relational database management system
(RDBMS). The popular ones you might have heard of are MySQL, PostgreSQL,
MariaDB, among (many) others.

Moving forward, I'll be talking in the context of SQL databases, since this is
the most common context where we see ACID guarantees in software systems.

### Atomicity

This means that more than one query can be sent to the database, and they will
either all succeed or nothing will happen. In databases, we call this a
transaction. This lets us try to make a big data transformation at just one
time, and then be promised that no side-effects will be left behind if part of
that transformation fails.

### Consistency

Hopefully, you know by now!

For SQL databases, this means that all constraints are checked for every write,
including referential integrity constraints, custom constraints, etc.

### Isolation

Multiple concurrent transactions can happen at the same time, and there won't
be any race conditions. This is another layer of consistency, and it means that
transactions will have to queue if they're trying to change the same data,
which slows things down and reduces availability.

### Durability

If you unplug the computer, you don't want to lose data. Once a SQL databases
tells you the query is complete, you could unplug the computer. The data would
still be there after starting it up. Again, consistency is the name of the
game, and this slows us down for the sake of correctness.

## BASE - What All the Cool Kids are Talking About

10 years after academics decided databases should always meet ACID guarantees,
the CAP Theorem informed us that it was practically impossible to do so. Well,
not impossible, but ACID equals absolute consistency. That means we either need
to partition or have low availability. Low availability for databases is rarely
acceptable, so we are left with one option: partitioning. As we learned
earlier, some data can't be partitioned! What is a fella to do??

BASE is an acronym / pun that remixes ACID with the CAP Theorem in mind. By
now, we already know what that means: it's going to describe a model with less
consistency. It turns out that for a lot of applications, we can make modest
consistency compromises and still serve the customer well.

BASE stands for:

- **b**asic **a**vailability: we're optimizing for availability
- **s**oft state: reads can lag behind writes. Writes need not be immediately
  reflected in reads
- **e**ventual consistency: data that was written will appear in reads
  eventually

Truly, an abhorrently shoehorned acronym.

Generally, BASE is accompanied by MongoDB proponents frothing at the mouth with
their virulent desire for availability, but we can achieve these things with
relational databases too by applying simple techniques:

- write queries can go into a durable queue, causing reads to lag behind writes
- we might choose to use fewer constraints on high traffic tables
    - the nice thing about SQL, is we can still use constraints as much as
      possible
    - we can benchmark and remove constraints only as necessary
    - in those cases, we can get smart with application logic to try to
      maintain some of the constraint
    - all together, we can walk the tightrope, striking a perfect balance
      between availability and consistency
- read replicas can lag behind the write replicas as much as we want

These techniques are pretty simple, straightforward, and widely supported by
any mature RDBMS. Don't let anyone tell you that ACID is inextricably tied to
SQL, and don't let anyone tell you that SQL inherently can't scale. Any system
that tries to have consistency, availability, and no partitioning will not
scale; that transcends SQL.

## CAP / ACID / BASE Challenges

Here are a few system design challenges. Identify which property of the CAP
Theorem the system should provide, and which ones we can skip.

### 1: Friends of Friends Social Media

Design a microservice that can tell you all the friends of friends for a user.
This will be used for friend recommendations, so it's not critical that the
system provides instantaneously up-to-date information. Syncing this service
with reality every few hours is acceptable. We want to render friend
recommendations for every page load. Clearly, we can cache the results for each
user, but the service should not be down. Users' friends of friends can span
any social network. We don't want to only find friends of friends in the same
town, for example. We don't want friends-of-friends to be constrained by any
data boundaries.

### 2: Algorithmic Trading

We want a bot that can perform trades on our behalf. The bot must know how much
money we have before making a trade, otherwise it might overdraw our account.
The bot cannot be down, or else we will miss out on profit.

### 3: Report Card Generator

We are creating a system to generate transcripts for students at a university.
Grades have to be absolutely accurate, no compromises. Unfortunately, we can't
separately process grades for a single department separately, because students
can take classes in any department, no matter what department their major is
in. We need to get transcripts printed sometime between April 15th and May 1st.
Transcription orders must be satisfied within 10 days.
